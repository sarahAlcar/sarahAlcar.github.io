---
---

@string{aps = {American Physical Society,}}

@article{carneiro2024clustering,
  bibtex_show={true},
  selected={true},
  title={Clustering Dynamics for Improved Speed Prediction Deriving from Topographical GPS Registrations},
  author={Carneiro, Sarah Almeida and Chierchia, Giovanni and Pirayre, Aurelie and Najman, Laurent},
  journal={arXiv preprint arXiv:2402.07507},
  year={2024},
  abstract={A persistent challenge in the field of Intelligent Transportation Systems is to extract accurate traffic insights from geographic regions with scarce or no data coverage. To this end, we propose solutions for speed prediction using sparse GPS data points and their associated topographical and road design features. Our goal is to investigate whether we can use similarities in the terrain and infrastructure to train a machine learning model that can predict speed in regions where we lack transportation data. For this, we create a Temporally Orientated Speed Dictionary Centered on Topographically Clustered Roads, which helps us to provide speed correlations to selected feature configurations. Our results show qualitative and quantitative improvement over new and standard regression methods. The presented framework provides a fresh perspective on devising strategies for missing data traffic analysis.},
  html={https://arxiv.org/abs/2402.07507},
  pdf={clust.pdf},
  preview={clust.png}
}

@inproceedings{carneiro2023swmlp,
  bibtex_show={true},
  selected={false},
  title={Swmlp: Shared weight multilayer perceptron for car trajectory speed prediction using road topographical features},
  author={Carneiro, Sarah Almeida and Chierchia, Giovanni and Charl{\'e}ty, Jean and Chataignon, Aur{\'e}lie and Najman, Laurent},
  booktitle={2023 8th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)},
  pages={1--6},
  year={2023},
  organization={IEEE},
  abstract = {Although traffic is one of the massively collected data, it is often only available for specific regions. One concern is that, although there are studies that give good results for these data, the data from these regions may not be sufficiently representative to describe all the traffic patterns in the rest of the world. In quest of addressing this concern, we propose a speed prediction method that is independent of large historical speed data. To predict a vehicle's speed, we use the trajectory road topographical features to fit a Shared Weight Multilayer Perceptron learning model. Our results show significant improvement, both qualitative and quantitative, over standard regression analysis. Moreover, the proposed framework sheds new light on the way to design new approaches for traffic analysis.},
  html={https://ieeexplore.ieee.org/document/10241394},
  pdf={swmlp.pdf},
  preview={swmlp.png}
}

@inproceedings{carneiro2019multi,
  bibtex_show={true},
  selected={true},
  title={Multi-stream deep convolutional network using high-level features applied to fall detection in video sequences},
  author={Carneiro, Sarah Almeida and da Silva, Gabriel Pellegrino and Leite, Guilherme Vieira and Moreno, Ricardo and Guimaraes, Silvio Jamil F and Pedrini, Helio},
  booktitle={2019 International Conference on Systems, Signals and Image Processing (IWSSIP)},
  pages={293--298},
  year={2019},
  organization={IEEE},
  abstract = {Sporadic falls, due to the lack of balance and other factors, are some of the complications that elderly people might experience more frequently than others. Accordingly, as there is a high probability of these events causing major health casualties, such as bone breaking or head clots, studies have been monitoring these falls to rapidly assist the victim. In this work, we propose and evaluate a multi-stream learning model based on convolutional neural networks using high-level handcrafted features as input in order to cope with this situation. Therefore, our approach consists of extracting high-level handcrafted features, for instance, human pose estimation and optical flow, and using each one as an input for a distinct VGG-16 classifier. In addition, these experiments are able to showcase what features can be used in fall detection. The results have shown that by assembling our directed input learners, our approach outperforms, in terms of accuracy and sensitivity rates, to other similar tested methods found in literature.},
  html={https://ieeexplore.ieee.org/document/8787213},
  pdf={multi.pdf},
  preview={multi.png}
}


@inproceedings{carneiro2019fight,
  bibtex_show={true},
  selected={false},
  title={Fight detection in video sequences based on multi-stream convolutional neural networks},
  author={Carneiro, Sarah Almeida and da Silva, Gabriel Pellegrino and Guimaraes, Silvio Jamil F and Pedrini, Helio},
  booktitle={2019 32nd SIBGRAPI conference on graphics, patterns and images (SIBGRAPI)},
  pages={8--15},
  year={2019},
  organization={IEEE},
  abstract = {Surveillance has been gradually correlating itself to forensic computer technologies. The use of machine learning techniques made possible the better interpretation of human actions, as well as faster identification of anomalous event outbursts. There are many studies regarding this field of expertise. The best results reported in the literature are from works related to deep learning approaches. Therefore, this study aimed to use a deep learning model based on a multi-stream and high level hand-crafted descriptors to be able to address the issue of fight detection in videos. In this work, we focused on the use of a multi-stream of VGG-16 networks and the investigation of conceivable feature descriptors of a video's spatial, temporal, rhythmic and depth information. We validated our method in two commonly used datasets, aimed at fight detection, throughout the literature. Experimentation has demonstrated that the association of correlated information with a multi-stream strategy increased the classification of our deep learning approach, hence, the use of complementary features can yield interesting outputs that are superior than other previous studies.},
  html={https://ieeexplore.ieee.org/document/8919750},
  pdf={fig.pdf},
  preview={fig.png}
}

@inproceedings{carneiro2018image,
  bibtex_show={true},
  selected={true},
  title={Image Inpainting Based on Local Patch Search Supported by Image Segmentation},
  author={Carneiro, Sarah Almeida and Pedrini, Helio and Guimar{\~a}es, Silvio Jamil Ferzoli},
  booktitle={Iberoamerican Congress on Pattern Recognition},
  pages={419--427},
  year={2018},
  organization={Springer},
  abstract = {Image inpainting can be defined as a restoration process in which damaged or selected regions are repaired by taking into account the image content. In this work, we employ a local-based strategy instead of a global one to identify the best existing patch with information to replace the damaged/selected patch. In order to properly identify the most representative patches, we propose a method based on the (i) creation of a local graph using a similarity of patches in the original image and (ii) partition of the image into regions according to hierarchical image segmentation to support the local patch identification. The experimental results demonstrate that our local search outperformed the results of image inpainting in terms of both qualitative and quantitative aspects, when compared to global search of patches.},
  html={https://ieeexplore.ieee.org/document/8919750},
  pdf={fig.pdf},
  preview={fig.png}
}

@inproceedings{jeronimo2021graph,
  bibtex_show={true},
  selected={true},
  title={Graph-based supervoxel computation from iterative spanning forest},
  author={Jer{\^o}nimo, Carolina and Bel{\'e}m, Felipe and Carneiro, Sarah A and Patroc{\'\i}nio Jr, Zenilton KG and Najman, Laurent and Falc{\~a}o, Alexandre and Guimar{\~a}es, Silvio Jamil F},
  booktitle={International Conference on Discrete Geometry and Mathematical Morphology},
  pages={404--415},
  year={2021},
  organization={Springer},
  abstract = {Supervoxel segmentation leads to major improvements in video analysis since it generates simpler but meaningful primitives (i.e., supervoxels). Thanks to the flexibility of the Iterative Spanning Forest (ISF) framework and recent strategies introduced by the Dynamic Iterative Spanning Forest (DISF) for superpixel computation, we propose a new graph-based method for supervoxel generation by using iterative spanning forest framework, so-called ISF2SVX, based on a pipeline composed by four stages: (a) graph creation; (b) seed oversampling; (c) IFT-based superpixel delineation; and (d) seed set reduction. Moreover, experimental results show that ISF2SVX is capable of effectively describing the videoâ€™s color variation through its supervoxels, while being competitive for the remaining metrics considered.},
  html={https://link.springer.com/chapter/10.1007/978-3-030-76657-3_29},
  pdf={voxel.pdf},
  preview={voxel.png}
}

